{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Title\n",
    "\n",
    "Description"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing packages."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing data into pandas DataFrame."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "      fire_size_class  latitude   longitude discovery_month  weekday  \\\n9402                B  34.29002  -80.968781             Jan     True   \n35119               G  32.61530 -112.109300             Jun     True   \n4965                B  35.30610  -92.087270             Jul     True   \n4060                B  47.66500 -120.508333             Aug     True   \n1986                C  43.63141 -102.564040             Sep     True   \n\n             Vegetation  remoteness  elevation       Temp      Wind  \\\n9402   Broadleaf Forest    0.125243      165.0   2.913529  0.758438   \n35119         Shrubland    0.225579      593.0  33.211757  2.307285   \n4965               Rock    0.225229      195.0  29.991118  2.998553   \n4060               Rock    0.497120     1021.0  20.431591  3.701693   \n1986          Grassland    0.320094      850.0  24.386706  4.860812   \n\n        Humidity  Precipitation  \n9402   22.334641       0.000000  \n35119  20.116564       0.000000  \n4965   63.461341       7.500000  \n4060   45.886931       2.333333  \n1986   48.769894       8.500000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fire_size_class</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>discovery_month</th>\n      <th>weekday</th>\n      <th>Vegetation</th>\n      <th>remoteness</th>\n      <th>elevation</th>\n      <th>Temp</th>\n      <th>Wind</th>\n      <th>Humidity</th>\n      <th>Precipitation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9402</th>\n      <td>B</td>\n      <td>34.29002</td>\n      <td>-80.968781</td>\n      <td>Jan</td>\n      <td>True</td>\n      <td>Broadleaf Forest</td>\n      <td>0.125243</td>\n      <td>165.0</td>\n      <td>2.913529</td>\n      <td>0.758438</td>\n      <td>22.334641</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>35119</th>\n      <td>G</td>\n      <td>32.61530</td>\n      <td>-112.109300</td>\n      <td>Jun</td>\n      <td>True</td>\n      <td>Shrubland</td>\n      <td>0.225579</td>\n      <td>593.0</td>\n      <td>33.211757</td>\n      <td>2.307285</td>\n      <td>20.116564</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4965</th>\n      <td>B</td>\n      <td>35.30610</td>\n      <td>-92.087270</td>\n      <td>Jul</td>\n      <td>True</td>\n      <td>Rock</td>\n      <td>0.225229</td>\n      <td>195.0</td>\n      <td>29.991118</td>\n      <td>2.998553</td>\n      <td>63.461341</td>\n      <td>7.500000</td>\n    </tr>\n    <tr>\n      <th>4060</th>\n      <td>B</td>\n      <td>47.66500</td>\n      <td>-120.508333</td>\n      <td>Aug</td>\n      <td>True</td>\n      <td>Rock</td>\n      <td>0.497120</td>\n      <td>1021.0</td>\n      <td>20.431591</td>\n      <td>3.701693</td>\n      <td>45.886931</td>\n      <td>2.333333</td>\n    </tr>\n    <tr>\n      <th>1986</th>\n      <td>C</td>\n      <td>43.63141</td>\n      <td>-102.564040</td>\n      <td>Sep</td>\n      <td>True</td>\n      <td>Grassland</td>\n      <td>0.320094</td>\n      <td>850.0</td>\n      <td>24.386706</td>\n      <td>4.860812</td>\n      <td>48.769894</td>\n      <td>8.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"fullDataFinal.csv\", index_col=0)\n",
    "df.columns = df.columns.str.strip()\n",
    "df.sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run this block to get the dataset with the all the features."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Separate target variable (fire_size_class) from predictor variables.\n",
    "\n",
    "dfTarget = df[\"fire_size_class\"]\n",
    "dfPredictor = df[[\"latitude\", \"longitude\", \"discovery_month\", \"weekday\", \"Vegetation\", \"remoteness\", \"elevation\", \"Temp\", \"Wind\", \"Humidity\", \"Precipitation\"]]\n",
    "\n",
    "# First we one-hot encode all of the classes\n",
    "dfTarget = pd.concat([dfTarget, pd.get_dummies(dfTarget)], axis=1)  # use get_dummies and concatenate the result to dfTarget\n",
    "dfTarget.drop([\"fire_size_class\"], axis=1, inplace=True)  # and remove the old column\n",
    "# print(dfTarget.sample(5))\n",
    "\n",
    "# We want to make it binary classification between B and the larger fires\n",
    "# To do this we can drop all classes other than B\n",
    "# If B is 0 -> it's larger\n",
    "dfTarget.drop([\"C\", \"D\", \"E\", \"F\", \"G\"], axis=1, inplace=True)\n",
    "print(dfTarget.sample(5))\n",
    "\n",
    "# Changing categorical variables into one-hot encoded ones.\n",
    "# Vegetation\n",
    "dfPredictor = pd.concat([dfPredictor, pd.get_dummies(dfPredictor[\"Vegetation\"], prefix=\"Veg\", prefix_sep=\" \")], axis=1)\n",
    "dfPredictor.drop([\"Vegetation\"], axis=1, inplace=True)\n",
    "# And discovery_month\n",
    "dfPredictor = pd.concat([dfPredictor, pd.get_dummies(dfPredictor[\"discovery_month\"])], axis=1)\n",
    "dfPredictor.drop([\"discovery_month\"], axis=1, inplace=True)\n",
    "# And weekday\n",
    "dfPredictor = pd.concat([dfPredictor, pd.get_dummies(dfPredictor[\"weekday\"])], axis=1)\n",
    "dfPredictor.drop([\"weekday\"], axis=1, inplace=True)\n",
    "dfPredictor.rename(columns={False:\"is_weekend\", True:\"is_weekday\"}, inplace=True)\n",
    "dfPredictor.sample(5)\n",
    "\n",
    "\n",
    "# Scaling numerical data to 0-1 range.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dfPredictorScaled = pd.DataFrame(MinMaxScaler().fit_transform(dfPredictor[[\"latitude\", \"longitude\", \"remoteness\", \"elevation\", \"Temp\", \"Wind\", \"Humidity\", \"Precipitation\"]]), columns=[\"latitude\", \"longitude\", \"remoteness\", \"elevation\", \"Temp\", \"Wind\", \"Humidity\", \"Precipitation\"])\n",
    "# dfPredictorScaled.sample(5)\n",
    "\n",
    "dfPredictor = dfPredictor.assign(**dfPredictorScaled.to_dict(orient=\"series\"))  # replace the columns of the old df with the ones from the new one\n",
    "dfPredictor.sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       B\n",
      "28865  1\n",
      "31113  0\n",
      "23486  1\n",
      "35851  0\n",
      "21185  1\n"
     ]
    },
    {
     "data": {
      "text/plain": "       latitude  longitude  remoteness  elevation      Temp      Wind  \\\n6668   0.361151   0.589965    0.359457   0.776193  0.557402  0.150894   \n21766  0.285001   0.703496    0.253949   0.044432  0.662829  0.061571   \n26992  0.324109   0.859755    0.111246   0.024685  0.489967  0.122379   \n33449  0.474498   0.524906    0.049418   0.473121  0.649207  0.090531   \n20341  0.265804   0.827214    0.142049   0.034833  0.535582  0.073624   \n\n       Humidity  Precipitation  Veg Broadleaf Forest  Veg Desert  ...  Jan  \\\n6668   0.305397       0.004872                     0           0  ...    0   \n21766  0.498025       0.000000                     0           0  ...    0   \n26992  0.599048       0.000682                     1           0  ...    0   \n33449  0.304629       0.000000                     0           0  ...    0   \n20341  0.780265       0.018292                     0           0  ...    0   \n\n       Jul  Jun  Mar  May  Nov  Oct  Sep  is_weekend  is_weekday  \n6668     0    1    0    0    0    0    0           0           1  \n21766    0    0    0    0    0    0    1           0           1  \n26992    0    0    0    0    1    0    0           0           1  \n33449    0    0    0    0    0    0    0           1           0  \n20341    0    0    0    0    1    0    0           0           1  \n\n[5 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>remoteness</th>\n      <th>elevation</th>\n      <th>Temp</th>\n      <th>Wind</th>\n      <th>Humidity</th>\n      <th>Precipitation</th>\n      <th>Veg Broadleaf Forest</th>\n      <th>Veg Desert</th>\n      <th>...</th>\n      <th>Jan</th>\n      <th>Jul</th>\n      <th>Jun</th>\n      <th>Mar</th>\n      <th>May</th>\n      <th>Nov</th>\n      <th>Oct</th>\n      <th>Sep</th>\n      <th>is_weekend</th>\n      <th>is_weekday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6668</th>\n      <td>0.361151</td>\n      <td>0.589965</td>\n      <td>0.359457</td>\n      <td>0.776193</td>\n      <td>0.557402</td>\n      <td>0.150894</td>\n      <td>0.305397</td>\n      <td>0.004872</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21766</th>\n      <td>0.285001</td>\n      <td>0.703496</td>\n      <td>0.253949</td>\n      <td>0.044432</td>\n      <td>0.662829</td>\n      <td>0.061571</td>\n      <td>0.498025</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26992</th>\n      <td>0.324109</td>\n      <td>0.859755</td>\n      <td>0.111246</td>\n      <td>0.024685</td>\n      <td>0.489967</td>\n      <td>0.122379</td>\n      <td>0.599048</td>\n      <td>0.000682</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33449</th>\n      <td>0.474498</td>\n      <td>0.524906</td>\n      <td>0.049418</td>\n      <td>0.473121</td>\n      <td>0.649207</td>\n      <td>0.090531</td>\n      <td>0.304629</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20341</th>\n      <td>0.265804</td>\n      <td>0.827214</td>\n      <td>0.142049</td>\n      <td>0.034833</td>\n      <td>0.535582</td>\n      <td>0.073624</td>\n      <td>0.780265</td>\n      <td>0.018292</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 28 columns</p>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the block below to get "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train-test split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33522, 28)\n",
      "(33522, 1) \n",
      "\n",
      "(3725, 28)\n",
      "(3725, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfPredictor, dfTarget, test_size=0.1, random_state=42, stratify=dfTarget)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape, \"\\n\")\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before SMOTEEN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[<AxesSubplot:title={'center':'B'}>]], dtype=object)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEICAYAAAC9E5gJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQlElEQVR4nO3df6zdd13H8eeLlcEo4AqV67JVi7Ek1i3CuNlqJHpxputmXGckcwvYbi7UwGb8sRir/lGyScJihskIDkto2hFgTARW3bA2dddFY+c6wf1CXB0dax0r0DEsE7Dz7R/nU3Ks9+6ennvuOb33Ph/Jyf2ez/l8v9/3+962r35/nHNTVUiSFreXjLoASdLoGQaSJMNAkmQYSJIwDCRJGAaSJAwDSRKGgTQQSQ4k+a8kR5M8m+TuJCtGXZfUK8NAGpxfrKpXAmcBzwAfGHE9Us8MA2nAquo7wKeA1aOuReqVYSANWJJXAL8C7B11LVKvloy6AGkB+WySY8BS4GvAxSOuR+qZRwbS4FxeVWcCLweuB/4uyQ+NtiSpN4aBNGBV9UJVfRp4AXjLqOuReuFpImnAkgS4DFgGfHHE5Ug9MQykwfnLJC8ABTwJbKyqR0dck9ST+MttJEleM5AkGQaSJMNAkoRhIEliHt9NtHz58lq5cmVf6377299m6dKlgy3oFGfPi8Ni63mx9Quz7/nBBx/8elX94Inj8zYMVq5cyb59+/pad3JykomJicEWdIqz58VhsfW82PqF2fec5Mmpxj1NJEkyDCRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIk5vE7kCVplFZuvnsk+92+bm4+fsMjA0mSYSBJMgwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJIkewiDJiiT3JnksyaNJfrONvybJ7iSPt6/L2niS3Jpkf5KHkpzfta2Nbf7jSTZ2jb85ycNtnVuTZC6alSRNrZcjg2PADVW1GlgDXJdkNbAZ2FNVq4A97TnAJcCq9tgE3Aad8AC2ABcCFwBbjgdIm/POrvXWzb41SVKvZgyDqnq6qv65Lf8n8EXgbGA9sKNN2wFc3pbXA7dXx17gzCRnARcDu6vqSFU9C+wG1rXXXl1Ve6uqgNu7tiVJGoKT+k1nSVYCbwLuB8aq6un20leBsbZ8NvBU12oH29iLjR+cYnyq/W+ic7TB2NgYk5OTJ1P+9x09erTvdecre14cFlvPo+z3hvOOjWS/c9Vzz2GQ5JXAXwC/VVXf6j6tX1WVpAZe3QmqaiuwFWB8fLwmJib62s7k5CT9rjtf2fPisNh6HmW/V4/w117ORc893U2U5KV0guBjVfXpNvxMO8VD+3q4jR8CVnStfk4be7Hxc6YYlyQNSS93EwX4CPDFqnp/10s7geN3BG0E7uoa39DuKloDPNdOJ+0C1iZZ1i4crwV2tde+lWRN29eGrm1Jkoagl9NEPw38KvBwki+0sT8A3gfcmeRa4EngivbaPcClwH7geeAagKo6kuQm4IE278aqOtKW3w1sB84APtcekqQhmTEMqurvgenu+79oivkFXDfNtrYB26YY3wecO1MtkqS54TuQJUmGgSTJMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJHoIgyTbkhxO8kjX2HuSHEryhfa4tOu130+yP8mXklzcNb6uje1Psrlr/PVJ7m/jn0xy+iAblCTNrJcjg+3AuinG/6Sq3tge9wAkWQ1cCfxEW+dPk5yW5DTgg8AlwGrgqjYX4Oa2rR8DngWunU1DkqSTN2MYVNV9wJEet7ceuKOqvltVXwb2Axe0x/6qeqKqvgfcAaxPEuDngE+19XcAl59cC5Kk2Voyi3WvT7IB2AfcUFXPAmcDe7vmHGxjAE+dMH4h8Frgm1V1bIr5/0+STcAmgLGxMSYnJ/sq/OjRo32vO1/Z8+Kw2HoeZb83nHds5klzYK567jcMbgNuAqp9vQX4tUEVNZ2q2gpsBRgfH6+JiYm+tjM5OUm/685X9rw4LLaeR9nv1ZvvHsl+t69bOic99xUGVfXM8eUkHwb+qj09BKzomnpOG2Oa8W8AZyZZ0o4OuudLkoakr1tLk5zV9fSXgON3Gu0ErkzysiSvB1YB/wQ8AKxqdw6dTuci886qKuBe4G1t/Y3AXf3UJEnq34xHBkk+AUwAy5McBLYAE0neSOc00QHg1wGq6tEkdwKPAceA66rqhbad64FdwGnAtqp6tO3i94A7kvwR8HngI4NqTpLUmxnDoKqummJ42n+wq+q9wHunGL8HuGeK8Sfo3G0kSRoR34EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKwZNQFjMLDh57j6s13D32/B973C0PfpyT1wiMDSZJhIEkyDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSfQQBkm2JTmc5JGusdck2Z3k8fZ1WRtPkluT7E/yUJLzu9bZ2OY/nmRj1/ibkzzc1rk1SQbdpCTpxfVyZLAdWHfC2GZgT1WtAva05wCXAKvaYxNwG3TCA9gCXAhcAGw5HiBtzju71jtxX5KkOTZjGFTVfcCRE4bXAzva8g7g8q7x26tjL3BmkrOAi4HdVXWkqp4FdgPr2muvrqq9VVXA7V3bkiQNSb8fYT1WVU+35a8CY235bOCprnkH29iLjR+cYnxKSTbROeJgbGyMycnJ/oo/A24471hf685Gv/UOwtGjR0e6/1Gw54VvlP2O4t8QmLueZ/37DKqqktQgiulhX1uBrQDj4+M1MTHR13Y+8LG7uOXh4f8qhwNvnxj6Po+bnJyk3+/XfGXPC98o+x3F70QB2L5u6Zz03O/dRM+0Uzy0r4fb+CFgRde8c9rYi42fM8W4JGmI+g2DncDxO4I2And1jW9odxWtAZ5rp5N2AWuTLGsXjtcCu9pr30qypt1FtKFrW5KkIZnxXEmSTwATwPIkB+ncFfQ+4M4k1wJPAle06fcAlwL7geeBawCq6kiSm4AH2rwbq+r4Rel307lj6Qzgc+0hSRqiGcOgqq6a5qWLpphbwHXTbGcbsG2K8X3AuTPVIUmaO74DWZJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgSWKWYZDkQJKHk3whyb429poku5M83r4ua+NJcmuS/UkeSnJ+13Y2tvmPJ9k4u5YkSSdrEEcGb62qN1bVeHu+GdhTVauAPe05wCXAqvbYBNwGnfAAtgAXAhcAW44HiCRpOObiNNF6YEdb3gFc3jV+e3XsBc5MchZwMbC7qo5U1bPAbmDdHNQlSZrGbMOggL9J8mCSTW1srKqebstfBcba8tnAU13rHmxj041LkoZkySzXf0tVHUryOmB3kn/tfrGqKknNch/f1wJnE8DY2BiTk5N9bWfsDLjhvGODKqtn/dY7CEePHh3p/kfBnhe+UfY7in9DYO56nlUYVNWh9vVwks/QOef/TJKzqurpdhrocJt+CFjRtfo5bewQMHHC+OQ0+9sKbAUYHx+viYmJqabN6AMfu4tbHp5tDp68A2+fGPo+j5ucnKTf79d8Zc8L3yj7vXrz3SPZ7/Z1S+ek575PEyVZmuRVx5eBtcAjwE7g+B1BG4G72vJOYEO7q2gN8Fw7nbQLWJtkWbtwvLaNSZKGZDb/PR4DPpPk+HY+XlV/neQB4M4k1wJPAle0+fcAlwL7geeBawCq6kiSm4AH2rwbq+rILOqSJJ2kvsOgqp4AfnKK8W8AF00xXsB102xrG7Ct31okSbPjO5AlSYaBJMkwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEqdQGCRZl+RLSfYn2TzqeiRpMTklwiDJacAHgUuA1cBVSVaPtipJWjxOiTAALgD2V9UTVfU94A5g/YhrkqRFY8moC2jOBp7qen4QuPDESUk2AZva06NJvtTn/pYDX+9z3b7l5mHv8f8YSc8jZs8L32Lrl7fePOuef2SqwVMlDHpSVVuBrbPdTpJ9VTU+gJLmDXteHBZbz4utX5i7nk+V00SHgBVdz89pY5KkIThVwuABYFWS1yc5HbgS2DnimiRp0TglThNV1bEk1wO7gNOAbVX16BzuctanmuYhe14cFlvPi61fmKOeU1VzsV1J0jxyqpwmkiSNkGEgSVrYYTDTR1wkeVmST7bX70+ycgRlDkwP/f5OkseSPJRkT5Ip7zeeT3r9GJMkv5ykksz72xB76TnJFe1n/WiSjw+7xkHr4c/2Dye5N8nn25/vS0dR56Ak2ZbkcJJHpnk9SW5t34+Hkpw/651W1YJ80LkQ/e/AjwKnA/8CrD5hzruBD7XlK4FPjrruOe73rcAr2vK75nO/vfbc5r0KuA/YC4yPuu4h/JxXAZ8HlrXnrxt13UPoeSvwrra8Gjgw6rpn2fPPAOcDj0zz+qXA54AAa4D7Z7vPhXxk0MtHXKwHdrTlTwEXJckQaxykGfutqnur6vn2dC+d93PMZ71+jMlNwM3Ad4ZZ3Bzpped3Ah+sqmcBqurwkGsctF56LuDVbfkHgP8YYn0DV1X3AUdeZMp64Pbq2AucmeSs2exzIYfBVB9xcfZ0c6rqGPAc8NqhVDd4vfTb7Vo6/7OYz2bsuR0+r6iqu4dZ2Bzq5ef8BuANSf4hyd4k64ZW3dzopef3AO9IchC4B/iN4ZQ2Mif7931Gp8T7DDRcSd4BjAM/O+pa5lKSlwDvB64ecSnDtoTOqaIJOkd/9yU5r6q+Ocqi5thVwPaquiXJTwEfTXJuVf3PqAubLxbykUEvH3Hx/TlJltA5vPzGUKobvJ4+0iPJzwN/CFxWVd8dUm1zZaaeXwWcC0wmOUDn3OrOeX4RuZef80FgZ1X9d1V9Gfg3OuEwX/XS87XAnQBV9Y/Ay+l8iN1CNfCP8FnIYdDLR1zsBDa25bcBf1vt6sw8NGO/Sd4E/BmdIJjv55Fhhp6r6rmqWl5VK6tqJZ3rJJdV1b7RlDsQvfy5/iydowKSLKdz2uiJIdY4aL30/BXgIoAkP04nDL421CqHayewod1VtAZ4rqqens0GF+xpoprmIy6S3Ajsq6qdwEfoHE7up3Ox5srRVTw7Pfb7x8ArgT9v18m/UlWXjazoWeqx5wWlx553AWuTPAa8APxuVc3XI95ee74B+HCS36ZzMfnqefwfO5J8gk6gL2/XQbYALwWoqg/RuS5yKbAfeB64Ztb7nMffL0nSgCzk00SSpB4ZBpIkw0CSZBhIkjAMJEkYBpIkDANJEvC/HEFAn65Zwk4AAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.hist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to fix the distribution of the data when training, we want to change it (in the training set only though).\n",
    "\n",
    "First, I tried randomly undersampling the data, however that made the training set too small (down to 2.6k samples total). The results were abysmal, with basically every model getting around a 2% accuracy on the test set.\n",
    "\n",
    "This is the code to do this, in case you want to (but you shouldn't)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23236, 28)\n",
      "(23236, 1)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We want to convert the y_train dataset from a Pandas DataFrame to a (n, ) Numpy array."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "y_train = y_train.values.ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, I tried the opposite approach -- random *over*sampling.\n",
    "\n",
    "Here, examples from the smaller classes are picked randomly and repeated in the dataset.\n",
    "\n",
    "This made the training set massive, at 130k+ samples, but it also made training take forever and didn't achieve great results.\n",
    "\n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "    ros = RandomOverSampler()\n",
    "    X_train, y_train = ros.fit_resample(X_train, y_train.values)\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "\n",
    "    y_train = pd.DataFrame(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\thesis\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2 3 4 5] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_train, y_train = smote_enn.fit_resample(X_train, y_train.to_numpy())\n",
    "y_train = pd.DataFrame(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After SMOTEEN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[<AxesSubplot:title={'center':'B'}>]], dtype=object)"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.hist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make a correlation matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "corrMatrix = X_train.corr()\n",
    "sn.heatmap(corrMatrix)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training models, each in a cell (?)\n",
    "\n",
    "* Dummy classifier\n",
    "* K-Nearest Neighbour (KNN)\n",
    "* NaÃ¯ve Bayes (NB)\n",
    "* Support Vector Machine (SVM)\n",
    "* Decision Tree (DT)\n",
    "* Random Forest (RF)\n",
    "* Gradient Boosted Trees (GBT)\n",
    "* Multi-Layered Perceptron (MLP)\n",
    "* Artificial Neural Network (ANN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluation with confusion matrix, F1 score, etc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dummy classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier()\n",
    "\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "training_accuracy = dummy_clf.score(X_train, y_train)\n",
    "test_accuracy = dummy_clf.score(X_test, y_test)\n",
    "print(f\"Training accuracy: {training_accuracy}\")  # 0.6537796074219915\n",
    "print(f\"Test accuracy: {test_accuracy}\")  # 0.6502013422818792\n",
    "\n",
    "\n",
    "y_true, y_pred = y_test , dummy_clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print('Results on the test set:')\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.5\n",
      "Test accuracy: 0.3465771812080537\n",
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      1.00      0.51      1291\n",
      "           1       0.00      0.00      0.00      2434\n",
      "\n",
      "    accuracy                           0.35      3725\n",
      "   macro avg       0.17      0.50      0.26      3725\n",
      "weighted avg       0.12      0.35      0.18      3725\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\thesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\pycharmprojects\\thesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\pycharmprojects\\thesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid = {'n_neighbors': range(2, 30, 2)}\n",
    "\n",
    "grid_searchKNN = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, n_jobs=-1)\n",
    "grid_searchKNN.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test set score: {:.2f}\".format(grid_searchKNN.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "y_true, y_pred = y_test , grid_searchKNN.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print('Results on the test set:')\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print(f\"Best test set score: {grid_searchKNN.best_score_} with {grid_searchKNN.best_params_} parameters.\")  # 0.6436993848306627 with {'n_neighbors': 25}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.69\n",
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.57      0.56      1291\n",
      "           1       0.77      0.76      0.76      2434\n",
      "\n",
      "    accuracy                           0.69      3725\n",
      "   macro avg       0.66      0.66      0.66      3725\n",
      "weighted avg       0.69      0.69      0.69      3725\n",
      "\n",
      "Best test set score: 0.6436993848306627 with {'n_neighbors': 25} parameters.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "25 seems to be the best on our test set. Let's train that model and save it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "clfKNN = KNeighborsClassifier(n_neighbors=9, n_jobs=-1)\n",
    "clfKNN.fit(X_train, y_train)\n",
    "\n",
    "training_accuracy = clfKNN.score(X_train, y_train)\n",
    "test_accuracy = clfKNN.score(X_test, y_test)\n",
    "print(\"Number of neighbors: 9\")\n",
    "print(f\"\\nTraining accuracy: {training_accuracy}\")  # 0.7298490543523656\n",
    "print(f\"\\nTest accuracy: {test_accuracy}\")  # 0.6934228187919463"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naive Bayes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "print(f\"GaussianNB train score: {gnb.score(X_train, y_train)}\")  # 0.21296462024938845\n",
    "print(f\"GaussianNB test score: {gnb.score(X_test, y_test)}\")  # 0.21986577181208053\n",
    "print(\"\\n\")\n",
    "\n",
    "y_true, y_pred = y_test , gnb.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print('Results on the test set:')\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB train score: 0.59330349457738\n",
      "GaussianNB test score: 0.6429530201342282\n",
      "\n",
      "\n",
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.51      0.50      1291\n",
      "           1       0.73      0.71      0.72      2434\n",
      "\n",
      "    accuracy                           0.64      3725\n",
      "   macro avg       0.61      0.61      0.61      3725\n",
      "weighted avg       0.65      0.64      0.65      3725\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Support Vector Machine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {'C': [0.01, 0.1, 0.25, 0.5, 0.75, 1]}\n",
    "\n",
    "grid_searchSVC = GridSearchCV(SVC(), param_grid, cv=5, n_jobs=-1)\n",
    "grid_searchSVC.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test set score: {:.2f}\".format(grid_searchSVC.score(X_test, y_test)))\n",
    "\n",
    "y_true, y_pred = y_test , grid_searchSVC.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print('Results on the test set:')\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.72\n",
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.48      0.55      1291\n",
      "           1       0.76      0.85      0.80      2434\n",
      "\n",
      "    accuracy                           0.72      3725\n",
      "   macro avg       0.69      0.67      0.67      3725\n",
      "weighted avg       0.71      0.72      0.71      3725\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best seems to be with C = ?\n",
    "\n",
    "Now lets train the final SVM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "svm = SVC(C = 0.25)\n",
    "multi_svm = MultiOutputClassifier(svm, n_jobs=-1)\n",
    "multi_svm.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Kernel SVM train score: {multi_svm.score(X_train, y_train)}\")  # 0.7018077680329335\n",
    "print(f\"Kernel SVM test score: {multi_svm.score(X_test, y_test)}\")  # 0.6977181208053691\n",
    "print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth': [4, 8, 16, 32, 64, 128, 256, 512], 'criterion': ['gini', 'entropy']}\n",
    "\n",
    "grid_searchDT = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, n_jobs=-1)\n",
    "grid_searchDT.fit(X_train, y_train)\n",
    "DT_ResultsDf = pd.DataFrame(grid_searchDT.cv_results_)\n",
    "\n",
    "print(DT_ResultsDf)\n",
    "print(f\"Best test set score: {grid_searchDT.best_score_} with {grid_searchDT.best_params_} parameters.\")\n",
    "\n",
    "y_true, y_pred = y_test , grid_searchDT.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print('Results on the test set:')\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        0.090305      0.001199         0.003997    6.468134e-07   \n",
      "1        0.165829      0.002604         0.003797    3.995420e-04   \n",
      "2        0.264329      0.003495         0.003797    3.994467e-04   \n",
      "3        0.297095      0.007779         0.004196    3.993043e-04   \n",
      "4        0.298693      0.005508         0.004396    4.894732e-04   \n",
      "5        0.298693      0.009392         0.003797    3.993512e-04   \n",
      "6        0.306086      0.011207         0.004396    4.890649e-04   \n",
      "7        0.301690      0.003739         0.004396    4.889282e-04   \n",
      "8        0.133662      0.003812         0.003997    6.314300e-04   \n",
      "9        0.239553      0.002558         0.003596    4.897652e-04   \n",
      "10       0.459329      0.021918         0.003797    3.992081e-04   \n",
      "11       0.574212      0.033062         0.006593    4.219602e-03   \n",
      "12       0.556829      0.058337         0.004196    3.994703e-04   \n",
      "13       0.526460      0.014830         0.004196    3.994945e-04   \n",
      "14       0.502685      0.009714         0.003796    3.993989e-04   \n",
      "15       0.421168      0.031493         0.003197    3.994232e-04   \n",
      "\n",
      "   param_criterion param_max_depth  \\\n",
      "0             gini               4   \n",
      "1             gini               8   \n",
      "2             gini              16   \n",
      "3             gini              32   \n",
      "4             gini              64   \n",
      "5             gini             128   \n",
      "6             gini             256   \n",
      "7             gini             512   \n",
      "8          entropy               4   \n",
      "9          entropy               8   \n",
      "10         entropy              16   \n",
      "11         entropy              32   \n",
      "12         entropy              64   \n",
      "13         entropy             128   \n",
      "14         entropy             256   \n",
      "15         entropy             512   \n",
      "\n",
      "                                        params  split0_test_score  \\\n",
      "0        {'criterion': 'gini', 'max_depth': 4}           0.655981   \n",
      "1        {'criterion': 'gini', 'max_depth': 8}           0.684165   \n",
      "2       {'criterion': 'gini', 'max_depth': 16}           0.649096   \n",
      "3       {'criterion': 'gini', 'max_depth': 32}           0.628657   \n",
      "4       {'criterion': 'gini', 'max_depth': 64}           0.632100   \n",
      "5      {'criterion': 'gini', 'max_depth': 128}           0.631239   \n",
      "6      {'criterion': 'gini', 'max_depth': 256}           0.629088   \n",
      "7      {'criterion': 'gini', 'max_depth': 512}           0.628657   \n",
      "8     {'criterion': 'entropy', 'max_depth': 4}           0.655766   \n",
      "9     {'criterion': 'entropy', 'max_depth': 8}           0.679647   \n",
      "10   {'criterion': 'entropy', 'max_depth': 16}           0.663296   \n",
      "11   {'criterion': 'entropy', 'max_depth': 32}           0.640491   \n",
      "12   {'criterion': 'entropy', 'max_depth': 64}           0.638554   \n",
      "13  {'criterion': 'entropy', 'max_depth': 128}           0.638339   \n",
      "14  {'criterion': 'entropy', 'max_depth': 256}           0.636188   \n",
      "15  {'criterion': 'entropy', 'max_depth': 512}           0.643718   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0            0.648806           0.641704           0.648375   \n",
      "1            0.676781           0.672692           0.672262   \n",
      "2            0.658920           0.642350           0.654616   \n",
      "3            0.642565           0.624919           0.635249   \n",
      "4            0.641489           0.621261           0.632021   \n",
      "5            0.639552           0.625780           0.632451   \n",
      "6            0.641920           0.619755           0.630514   \n",
      "7            0.640413           0.619109           0.630514   \n",
      "8            0.648806           0.641704           0.648806   \n",
      "9            0.678072           0.667958           0.675490   \n",
      "10           0.661932           0.648160           0.657844   \n",
      "11           0.645793           0.629008           0.637400   \n",
      "12           0.638692           0.627932           0.638907   \n",
      "13           0.640628           0.630299           0.634173   \n",
      "14           0.637400           0.634173           0.636755   \n",
      "15           0.645147           0.627932           0.632236   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0            0.650312         0.649036        0.004563                5  \n",
      "1            0.675920         0.676364        0.004279                1  \n",
      "2            0.642780         0.649552        0.006501                4  \n",
      "3            0.624704         0.631219        0.006836               12  \n",
      "4            0.627286         0.630831        0.006645               13  \n",
      "5            0.621691         0.630143        0.006091               14  \n",
      "6            0.621476         0.628551        0.007878               15  \n",
      "7            0.623843         0.628507        0.007154               16  \n",
      "8            0.649666         0.648950        0.004461                6  \n",
      "9            0.672262         0.674686        0.004192                2  \n",
      "10           0.643856         0.655018        0.007693                3  \n",
      "11           0.619755         0.634489        0.009159                7  \n",
      "12           0.617818         0.632381        0.008395               11  \n",
      "13           0.620615         0.632811        0.007051               10  \n",
      "14           0.619539         0.632811        0.006723                9  \n",
      "15           0.618894         0.633585        0.009859                8  \n",
      "Best test set score: 0.676363926609324 with {'criterion': 'gini', 'max_depth': 8} parameters.\n",
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.62      0.60      1291\n",
      "           1       0.79      0.76      0.78      2434\n",
      "\n",
      "    accuracy                           0.71      3725\n",
      "   macro avg       0.69      0.69      0.69      3725\n",
      "weighted avg       0.72      0.71      0.71      3725\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best max_depth is 5 -->  0.72060144"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Decision Tree train score: {dt.score(X_train, y_train)}\")  # 0.7240618101545254\n",
    "print(f\"Decision Tree test score: {dt.score(X_test, y_test)}\")  # 0.7103355704697987\n",
    "print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth': [4, 8, 16, 32, 64, 128, 256, 512], 'n_estimators': [100, 500, 1000], 'criterion': ['gini', 'entropy']}\n",
    "\n",
    "grid_searchRF = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, n_jobs=-1)\n",
    "grid_searchRF.fit(X_train, y_train)\n",
    "RF_ResultsDf = pd.DataFrame(grid_searchRF.cv_results_)\n",
    "\n",
    "print(RF_ResultsDf)\n",
    "print(f\"Best test set score: {grid_searchRF.best_score_} with {grid_searchRF.best_params_} parameters.\")\n",
    "\n",
    "\n",
    "y_true, y_pred = y_test , grid_searchRF.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print('Results on the test set:')\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        1.310457      0.015876         0.046753        0.000748   \n",
      "1        6.546496      0.112534         0.214779        0.005650   \n",
      "2       13.206278      0.236400         0.420769        0.005906   \n",
      "3        2.390752      0.069540         0.069729        0.012690   \n",
      "4       11.044292      0.095473         0.294099        0.001623   \n",
      "5       22.104567      0.085902         0.596789        0.014304   \n",
      "6        3.666845      0.051906         0.108689        0.002225   \n",
      "7       18.456303      0.178604         0.548438        0.009435   \n",
      "8       38.444237      0.400869         1.139034        0.048136   \n",
      "9        4.490202      0.040899         0.141656        0.003121   \n",
      "10      23.264179      0.340181         0.705079        0.009401   \n",
      "11      45.378338      0.158833         1.436329        0.013660   \n",
      "12       4.614875      0.045619         0.148049        0.009381   \n",
      "13      22.653006      0.235129         0.704479        0.015800   \n",
      "14      45.338778      0.244722         1.481683        0.038691   \n",
      "15       4.524368      0.029822         0.144852        0.009090   \n",
      "16      22.522939      0.218662         0.714868        0.016652   \n",
      "17      45.788118      0.311682         1.494070        0.040181   \n",
      "18       4.572918      0.020884         0.141455        0.005707   \n",
      "19      22.700357      0.111779         0.714868        0.018176   \n",
      "20      45.319198      0.189391         1.473092        0.023390   \n",
      "21       4.528362      0.065086         0.143254        0.003975   \n",
      "22      22.700956      0.352882         0.706877        0.027472   \n",
      "23      45.637272      0.451772         1.417748        0.045011   \n",
      "24       1.814941      0.031193         0.044754        0.000748   \n",
      "25       9.054529      0.080360         0.212383        0.005566   \n",
      "26      18.208756      0.086254         0.413776        0.003426   \n",
      "27       3.299221      0.062739         0.058541        0.000800   \n",
      "28      16.211601      0.068314         0.285108        0.005879   \n",
      "29      32.520902      0.247842         0.555032        0.009821   \n",
      "30       5.614451      0.055790         0.095702        0.002225   \n",
      "31      28.097031      0.102662         0.467921        0.015224   \n",
      "32      56.119340      0.212166         0.955822        0.012531   \n",
      "33       7.054376      0.047535         0.129868        0.003894   \n",
      "34      35.513637      0.236305         0.630754        0.008514   \n",
      "35      70.999704      0.538091         1.281488        0.014232   \n",
      "36       7.127102      0.069112         0.131066        0.008854   \n",
      "37      35.671676      0.298866         0.641143        0.021092   \n",
      "38      72.326345      0.579255         1.333035        0.022200   \n",
      "39       7.100130      0.056226         0.129867        0.004853   \n",
      "40      35.971369      0.136733         0.642942        0.015954   \n",
      "41      71.699387      0.744046         1.363005        0.043354   \n",
      "42       7.121907      0.055905         0.129268        0.005117   \n",
      "43      35.695651      0.157234         0.656728        0.017007   \n",
      "44      71.903778      0.276077         1.361606        0.041733   \n",
      "45       7.146082      0.092675         0.129268        0.003607   \n",
      "46      34.981182      1.199392         0.618966        0.033537   \n",
      "47      61.674851      0.387123         1.098875        0.103082   \n",
      "\n",
      "   param_criterion param_max_depth param_n_estimators  \\\n",
      "0             gini               4                100   \n",
      "1             gini               4                500   \n",
      "2             gini               4               1000   \n",
      "3             gini               8                100   \n",
      "4             gini               8                500   \n",
      "5             gini               8               1000   \n",
      "6             gini              16                100   \n",
      "7             gini              16                500   \n",
      "8             gini              16               1000   \n",
      "9             gini              32                100   \n",
      "10            gini              32                500   \n",
      "11            gini              32               1000   \n",
      "12            gini              64                100   \n",
      "13            gini              64                500   \n",
      "14            gini              64               1000   \n",
      "15            gini             128                100   \n",
      "16            gini             128                500   \n",
      "17            gini             128               1000   \n",
      "18            gini             256                100   \n",
      "19            gini             256                500   \n",
      "20            gini             256               1000   \n",
      "21            gini             512                100   \n",
      "22            gini             512                500   \n",
      "23            gini             512               1000   \n",
      "24         entropy               4                100   \n",
      "25         entropy               4                500   \n",
      "26         entropy               4               1000   \n",
      "27         entropy               8                100   \n",
      "28         entropy               8                500   \n",
      "29         entropy               8               1000   \n",
      "30         entropy              16                100   \n",
      "31         entropy              16                500   \n",
      "32         entropy              16               1000   \n",
      "33         entropy              32                100   \n",
      "34         entropy              32                500   \n",
      "35         entropy              32               1000   \n",
      "36         entropy              64                100   \n",
      "37         entropy              64                500   \n",
      "38         entropy              64               1000   \n",
      "39         entropy             128                100   \n",
      "40         entropy             128                500   \n",
      "41         entropy             128               1000   \n",
      "42         entropy             256                100   \n",
      "43         entropy             256                500   \n",
      "44         entropy             256               1000   \n",
      "45         entropy             512                100   \n",
      "46         entropy             512                500   \n",
      "47         entropy             512               1000   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "0   {'criterion': 'gini', 'max_depth': 4, 'n_estim...           0.649312   \n",
      "1   {'criterion': 'gini', 'max_depth': 4, 'n_estim...           0.653184   \n",
      "2   {'criterion': 'gini', 'max_depth': 4, 'n_estim...           0.651678   \n",
      "3   {'criterion': 'gini', 'max_depth': 8, 'n_estim...           0.681799   \n",
      "4   {'criterion': 'gini', 'max_depth': 8, 'n_estim...           0.683305   \n",
      "5   {'criterion': 'gini', 'max_depth': 8, 'n_estim...           0.682229   \n",
      "6   {'criterion': 'gini', 'max_depth': 16, 'n_esti...           0.688898   \n",
      "7   {'criterion': 'gini', 'max_depth': 16, 'n_esti...           0.689974   \n",
      "8   {'criterion': 'gini', 'max_depth': 16, 'n_esti...           0.692556   \n",
      "9   {'criterion': 'gini', 'max_depth': 32, 'n_esti...           0.677281   \n",
      "10  {'criterion': 'gini', 'max_depth': 32, 'n_esti...           0.689114   \n",
      "11  {'criterion': 'gini', 'max_depth': 32, 'n_esti...           0.690835   \n",
      "12  {'criterion': 'gini', 'max_depth': 64, 'n_esti...           0.685456   \n",
      "13  {'criterion': 'gini', 'max_depth': 64, 'n_esti...           0.694707   \n",
      "14  {'criterion': 'gini', 'max_depth': 64, 'n_esti...           0.687392   \n",
      "15  {'criterion': 'gini', 'max_depth': 128, 'n_est...           0.687823   \n",
      "16  {'criterion': 'gini', 'max_depth': 128, 'n_est...           0.689544   \n",
      "17  {'criterion': 'gini', 'max_depth': 128, 'n_est...           0.688038   \n",
      "18  {'criterion': 'gini', 'max_depth': 256, 'n_est...           0.686532   \n",
      "19  {'criterion': 'gini', 'max_depth': 256, 'n_est...           0.687823   \n",
      "20  {'criterion': 'gini', 'max_depth': 256, 'n_est...           0.685456   \n",
      "21  {'criterion': 'gini', 'max_depth': 512, 'n_est...           0.683950   \n",
      "22  {'criterion': 'gini', 'max_depth': 512, 'n_est...           0.690835   \n",
      "23  {'criterion': 'gini', 'max_depth': 512, 'n_est...           0.689974   \n",
      "24  {'criterion': 'entropy', 'max_depth': 4, 'n_es...           0.650818   \n",
      "25  {'criterion': 'entropy', 'max_depth': 4, 'n_es...           0.651033   \n",
      "26  {'criterion': 'entropy', 'max_depth': 4, 'n_es...           0.650818   \n",
      "27  {'criterion': 'entropy', 'max_depth': 8, 'n_es...           0.678141   \n",
      "28  {'criterion': 'entropy', 'max_depth': 8, 'n_es...           0.674484   \n",
      "29  {'criterion': 'entropy', 'max_depth': 8, 'n_es...           0.677926   \n",
      "30  {'criterion': 'entropy', 'max_depth': 16, 'n_e...           0.691910   \n",
      "31  {'criterion': 'entropy', 'max_depth': 16, 'n_e...           0.691910   \n",
      "32  {'criterion': 'entropy', 'max_depth': 16, 'n_e...           0.691910   \n",
      "33  {'criterion': 'entropy', 'max_depth': 32, 'n_e...           0.689544   \n",
      "34  {'criterion': 'entropy', 'max_depth': 32, 'n_e...           0.690620   \n",
      "35  {'criterion': 'entropy', 'max_depth': 32, 'n_e...           0.693847   \n",
      "36  {'criterion': 'entropy', 'max_depth': 64, 'n_e...           0.685456   \n",
      "37  {'criterion': 'entropy', 'max_depth': 64, 'n_e...           0.689544   \n",
      "38  {'criterion': 'entropy', 'max_depth': 64, 'n_e...           0.689544   \n",
      "39  {'criterion': 'entropy', 'max_depth': 128, 'n_...           0.685456   \n",
      "40  {'criterion': 'entropy', 'max_depth': 128, 'n_...           0.688898   \n",
      "41  {'criterion': 'entropy', 'max_depth': 128, 'n_...           0.690835   \n",
      "42  {'criterion': 'entropy', 'max_depth': 256, 'n_...           0.681368   \n",
      "43  {'criterion': 'entropy', 'max_depth': 256, 'n_...           0.687392   \n",
      "44  {'criterion': 'entropy', 'max_depth': 256, 'n_...           0.692771   \n",
      "45  {'criterion': 'entropy', 'max_depth': 512, 'n_...           0.685671   \n",
      "46  {'criterion': 'entropy', 'max_depth': 512, 'n_...           0.687392   \n",
      "47  {'criterion': 'entropy', 'max_depth': 512, 'n_...           0.690189   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0            0.645578           0.637400           0.641704   \n",
      "1            0.646869           0.635249           0.639983   \n",
      "2            0.645147           0.638046           0.644502   \n",
      "3            0.676996           0.664515           0.664300   \n",
      "4            0.676350           0.664945           0.666451   \n",
      "5            0.677426           0.661717           0.666451   \n",
      "6            0.691414           0.693781           0.689477   \n",
      "7            0.692490           0.690338           0.692920   \n",
      "8            0.692490           0.688616           0.690983   \n",
      "9            0.690983           0.693351           0.681945   \n",
      "10           0.690338           0.681730           0.686895   \n",
      "11           0.692275           0.688401           0.688832   \n",
      "12           0.694642           0.684097           0.683021   \n",
      "13           0.696794           0.686034           0.688186   \n",
      "14           0.693351           0.689262           0.684528   \n",
      "15           0.694642           0.687325           0.689907   \n",
      "16           0.686249           0.689907           0.684958   \n",
      "17           0.691844           0.685819           0.687756   \n",
      "18           0.690338           0.686680           0.685819   \n",
      "19           0.692059           0.685173           0.684743   \n",
      "20           0.692705           0.693135           0.688832   \n",
      "21           0.694427           0.682806           0.679578   \n",
      "22           0.692490           0.687971           0.685173   \n",
      "23           0.694857           0.692059           0.687540   \n",
      "24           0.646008           0.637400           0.640628   \n",
      "25           0.644287           0.634173           0.642565   \n",
      "26           0.646869           0.637400           0.642350   \n",
      "27           0.673983           0.661932           0.662578   \n",
      "28           0.675274           0.662148           0.666021   \n",
      "29           0.675490           0.661932           0.666882   \n",
      "30           0.687110           0.693566           0.686034   \n",
      "31           0.693996           0.693566           0.689692   \n",
      "32           0.692705           0.687325           0.693135   \n",
      "33           0.692275           0.690123           0.682806   \n",
      "34           0.690553           0.689477           0.687756   \n",
      "35           0.692705           0.689262           0.685173   \n",
      "36           0.685819           0.685173           0.680009   \n",
      "37           0.691199           0.685819           0.687540   \n",
      "38           0.691629           0.684528           0.684312   \n",
      "39           0.689262           0.686464           0.682591   \n",
      "40           0.696363           0.689262           0.685819   \n",
      "41           0.691844           0.689907           0.686895   \n",
      "42           0.690983           0.687110           0.684312   \n",
      "43           0.691414           0.685819           0.687110   \n",
      "44           0.695072           0.687110           0.685604   \n",
      "45           0.687971           0.682376           0.689692   \n",
      "46           0.693996           0.687325           0.685604   \n",
      "47           0.695502           0.684743           0.687110   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0            0.640628         0.642924        0.004126               47  \n",
      "1            0.640844         0.643226        0.006201               45  \n",
      "2            0.641489         0.644173        0.004519               43  \n",
      "3            0.666236         0.670769        0.007238               39  \n",
      "4            0.668388         0.671888        0.006932               37  \n",
      "5            0.666882         0.670941        0.007631               38  \n",
      "6            0.694211         0.691556        0.002164                6  \n",
      "7            0.696794         0.692503        0.002436                2  \n",
      "8            0.696578         0.692245        0.002596                3  \n",
      "9            0.687325         0.686177        0.005881               33  \n",
      "10           0.693781         0.688371        0.003999               27  \n",
      "11           0.696794         0.691427        0.003025                8  \n",
      "12           0.684743         0.686392        0.004202               31  \n",
      "13           0.693135         0.691771        0.004037                5  \n",
      "14           0.694857         0.689878        0.003796               17  \n",
      "15           0.689692         0.689878        0.002587               18  \n",
      "16           0.690338         0.688199        0.002173               28  \n",
      "17           0.693781         0.689447        0.002917               21  \n",
      "18           0.689262         0.687726        0.001752               29  \n",
      "19           0.696794         0.689318        0.004555               22  \n",
      "20           0.693135         0.690653        0.003061               13  \n",
      "21           0.687971         0.685746        0.005103               35  \n",
      "22           0.692920         0.689878        0.002925               19  \n",
      "23           0.692920         0.691470        0.002514                7  \n",
      "24           0.638692         0.642709        0.005006               48  \n",
      "25           0.643641         0.643140        0.005378               46  \n",
      "26           0.642135         0.643914        0.004570               44  \n",
      "27           0.665376         0.668402        0.006495               42  \n",
      "28           0.664730         0.668531        0.005337               41  \n",
      "29           0.663008         0.669048        0.006513               40  \n",
      "30           0.691844         0.690093        0.002960               16  \n",
      "31           0.695933         0.693020        0.002100                1  \n",
      "32           0.695072         0.692030        0.002572                4  \n",
      "33           0.689692         0.688888        0.003196               25  \n",
      "34           0.694857         0.690652        0.002344               14  \n",
      "35           0.695287         0.691255        0.003634                9  \n",
      "36           0.691844         0.685660        0.003755               36  \n",
      "37           0.691844         0.689189        0.002249               23  \n",
      "38           0.693351         0.688673        0.003676               26  \n",
      "39           0.687540         0.686263        0.002227               32  \n",
      "40           0.695287         0.691126        0.004034               10  \n",
      "41           0.693996         0.690695        0.002337               12  \n",
      "42           0.685819         0.685919        0.003174               34  \n",
      "43           0.692705         0.688888        0.002675               24  \n",
      "44           0.693351         0.690781        0.003722               11  \n",
      "45           0.687110         0.686564        0.002466               30  \n",
      "46           0.694857         0.689835        0.003813               20  \n",
      "47           0.693996         0.690308        0.004045               15  \n",
      "Best test set score: 0.6930195003013067 with {'criterion': 'entropy', 'max_depth': 16, 'n_estimators': 500} parameters.\n",
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62      1291\n",
      "           1       0.80      0.81      0.81      2434\n",
      "\n",
      "    accuracy                           0.74      3725\n",
      "   macro avg       0.72      0.71      0.71      3725\n",
      "weighted avg       0.74      0.74      0.74      3725\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best seems to be with max_depth=12"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "rf = RandomForestClassifier(max_depth=12, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Random Forest train score: {rf.score(X_train, y_train)}\")  # 0.7210786945886284\n",
    "print(f\"Random Forest test score: {rf.score(X_test, y_test)}\")  # 0.6877852348993289\n",
    "print(\"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient Boosted Trees (GBT)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth':[2,4,8,16,30,40], 'loss':['deviance', 'exponential']}\n",
    "\n",
    "grid_searchGBT = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, n_jobs=-1)\n",
    "grid_searchGBT.fit(X_train, y_train)\n",
    "GBT_ResultsDf = pd.DataFrame(grid_searchGBT.cv_results_)\n",
    "\n",
    "print(GBT_ResultsDf)\n",
    "print(f\"Best test set score: {grid_searchGBT.best_score_} with {grid_searchGBT.best_params_} parameters.\")\n",
    "\n",
    "y_true, y_pred = y_test , grid_searchGBT.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print('Results on the test set:')\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time   param_loss  \\\n",
      "0        4.328169      0.199383         0.010190        0.000979     deviance   \n",
      "1        7.887125      0.200798         0.012986        0.000631     deviance   \n",
      "2       15.895523      0.130179         0.020379        0.001355     deviance   \n",
      "3       38.067223      0.326768         0.042557        0.001355     deviance   \n",
      "4       62.989905      2.541507         0.088709        0.008415     deviance   \n",
      "5       58.718878      0.827659         0.087910        0.005508     deviance   \n",
      "6        3.943162      0.027810         0.009190        0.000400  exponential   \n",
      "7        7.664752      0.058801         0.012587        0.000489  exponential   \n",
      "8       15.488541      0.067889         0.020379        0.000490  exponential   \n",
      "9       40.177063      0.505294         0.044754        0.001325  exponential   \n",
      "10      71.472819      3.095950         0.085313        0.012865  exponential   \n",
      "11      57.193240      8.443523         0.071727        0.005109  exponential   \n",
      "\n",
      "   param_max_depth                                    params  \\\n",
      "0                2      {'loss': 'deviance', 'max_depth': 2}   \n",
      "1                4      {'loss': 'deviance', 'max_depth': 4}   \n",
      "2                8      {'loss': 'deviance', 'max_depth': 8}   \n",
      "3               16     {'loss': 'deviance', 'max_depth': 16}   \n",
      "4               30     {'loss': 'deviance', 'max_depth': 30}   \n",
      "5               40     {'loss': 'deviance', 'max_depth': 40}   \n",
      "6                2   {'loss': 'exponential', 'max_depth': 2}   \n",
      "7                4   {'loss': 'exponential', 'max_depth': 4}   \n",
      "8                8   {'loss': 'exponential', 'max_depth': 8}   \n",
      "9               16  {'loss': 'exponential', 'max_depth': 16}   \n",
      "10              30  {'loss': 'exponential', 'max_depth': 30}   \n",
      "11              40  {'loss': 'exponential', 'max_depth': 40}   \n",
      "\n",
      "    split0_test_score  split1_test_score  split2_test_score  \\\n",
      "0            0.671687           0.666667           0.658705   \n",
      "1            0.685886           0.686680           0.685173   \n",
      "2            0.679002           0.690553           0.682376   \n",
      "3            0.675129           0.682806           0.680439   \n",
      "4            0.637694           0.642135           0.623413   \n",
      "5            0.630164           0.640628           0.623413   \n",
      "6            0.669105           0.665806           0.658920   \n",
      "7            0.686747           0.686034           0.686464   \n",
      "8            0.685241           0.695502           0.691414   \n",
      "9            0.684811           0.692920           0.678717   \n",
      "10           0.630809           0.648590           0.626426   \n",
      "11           0.629518           0.637616           0.624704   \n",
      "\n",
      "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
      "0            0.661287           0.668173         0.665304        0.004701   \n",
      "1            0.683667           0.687325         0.685746        0.001268   \n",
      "2            0.694642           0.689692         0.687253        0.005715   \n",
      "3            0.673553           0.681515         0.678688        0.003662   \n",
      "4            0.632451           0.627502         0.632639        0.006742   \n",
      "5            0.634388           0.626641         0.631047        0.006024   \n",
      "6            0.660856           0.665591         0.664056        0.003675   \n",
      "7            0.678072           0.686249         0.684713        0.003329   \n",
      "8            0.689477           0.687756         0.689878        0.003469   \n",
      "9            0.679363           0.690338         0.685230        0.005696   \n",
      "10           0.640413           0.626641         0.634576        0.008649   \n",
      "11           0.633097           0.623413         0.629669        0.005267   \n",
      "\n",
      "    rank_test_score  \n",
      "0                 7  \n",
      "1                 3  \n",
      "2                 2  \n",
      "3                 6  \n",
      "4                10  \n",
      "5                11  \n",
      "6                 8  \n",
      "7                 5  \n",
      "8                 1  \n",
      "9                 4  \n",
      "10                9  \n",
      "11               12  \n",
      "Best test set score: 0.689877975426561 with {'loss': 'exponential', 'max_depth': 8} parameters.\n",
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1291\n",
      "           1       0.81      0.79      0.80      2434\n",
      "\n",
      "    accuracy                           0.74      3725\n",
      "   macro avg       0.71      0.72      0.71      3725\n",
      "weighted avg       0.74      0.74      0.74      3725\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-Layered Perceptron (MLP)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(5), (5, 5), (10), (10, 10), (10, 5), (5, 10, 5), (15, 30, 15), (5, 10, 10, 5), (15, 30, 5)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant']\n",
    "}\n",
    "\n",
    "grid_searchMLP = GridSearchCV(MLPClassifier(max_iter=10000), param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "grid_searchMLP.fit(X_train, y_train)\n",
    "MLP_ResultsDf = pd.DataFrame(grid_searchMLP.cv_results_)\n",
    "\n",
    "print(MLP_ResultsDf)\n",
    "print(f\"Best test set score: {grid_searchMLP.best_score_} with {grid_searchMLP.best_params_} parameters.\")\n",
    "\n",
    "y_true, y_pred = y_test , grid_searchMLP.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print('Results on the test set:')\n",
    "print(classification_report(y_true, y_pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       19.404132      2.160922         0.004995    1.168008e-07   \n",
      "1       21.387702      3.315974         0.005794    7.476146e-04   \n",
      "2       23.851379      2.584907         0.005794    3.995181e-04   \n",
      "3       20.937162      1.584407         0.006194    3.997567e-04   \n",
      "4       18.915832      2.266775         0.006194    3.994944e-04   \n",
      "5       20.225492      6.483543         0.006193    3.995667e-04   \n",
      "6       22.543118      2.191165         0.011189    3.999235e-04   \n",
      "7       19.637493      2.592764         0.007992    3.162980e-07   \n",
      "8       27.296051      6.570260         0.009990    4.523674e-07   \n",
      "9       11.371356      1.946801         0.004795    3.996611e-04   \n",
      "10      16.702698      2.600532         0.005594    4.886559e-04   \n",
      "11      15.373859      2.569150         0.004995    3.162980e-07   \n",
      "12      16.125688      3.182139         0.006393    4.892591e-04   \n",
      "13      15.451779      1.229246         0.005994    3.873843e-07   \n",
      "14      17.337049      7.811734         0.005994    6.318820e-04   \n",
      "15      16.006411      4.733622         0.010190    3.997089e-04   \n",
      "16      11.996516      4.108431         0.006993    4.422006e-07   \n",
      "17      17.285501      3.223663         0.009191    3.994704e-04   \n",
      "18      13.649624      2.470560         0.004196    3.993991e-04   \n",
      "19      15.328305      2.985577         0.004995    8.936160e-04   \n",
      "20      16.420787      1.520084         0.004995    6.315805e-04   \n",
      "21      17.796977      3.409338         0.005794    7.475126e-04   \n",
      "22      17.134456      2.913031         0.004995    2.431402e-07   \n",
      "23      16.854543      4.119715         0.005594    4.892201e-04   \n",
      "24      19.409127      4.762953         0.013187    4.950862e-03   \n",
      "25      20.935963      2.940154         0.007792    1.164969e-03   \n",
      "26      17.435148      3.570069         0.009590    2.056675e-03   \n",
      "27       9.876887      2.432749         0.004796    7.473215e-04   \n",
      "28      14.498755      3.150350         0.005195    3.994942e-04   \n",
      "29      14.959084      2.403807         0.005395    1.018365e-03   \n",
      "30      12.481220      2.084459         0.005594    4.893759e-04   \n",
      "31      17.187002      3.105920         0.005195    1.165002e-03   \n",
      "32      15.870150      3.269847         0.006194    1.598007e-03   \n",
      "33      14.616234      2.910466         0.010590    2.725051e-03   \n",
      "34      19.846878      3.366105         0.007592    1.018711e-03   \n",
      "35      13.025463      3.616297         0.007392    2.151776e-03   \n",
      "\n",
      "   param_activation param_alpha param_hidden_layer_sizes param_learning_rate  \\\n",
      "0              tanh      0.0001                        5            constant   \n",
      "1              tanh      0.0001                   (5, 5)            constant   \n",
      "2              tanh      0.0001                       10            constant   \n",
      "3              tanh      0.0001                 (10, 10)            constant   \n",
      "4              tanh      0.0001                  (10, 5)            constant   \n",
      "5              tanh      0.0001               (5, 10, 5)            constant   \n",
      "6              tanh      0.0001             (15, 30, 15)            constant   \n",
      "7              tanh      0.0001           (5, 10, 10, 5)            constant   \n",
      "8              tanh      0.0001              (15, 30, 5)            constant   \n",
      "9              tanh        0.05                        5            constant   \n",
      "10             tanh        0.05                   (5, 5)            constant   \n",
      "11             tanh        0.05                       10            constant   \n",
      "12             tanh        0.05                 (10, 10)            constant   \n",
      "13             tanh        0.05                  (10, 5)            constant   \n",
      "14             tanh        0.05               (5, 10, 5)            constant   \n",
      "15             tanh        0.05             (15, 30, 15)            constant   \n",
      "16             tanh        0.05           (5, 10, 10, 5)            constant   \n",
      "17             tanh        0.05              (15, 30, 5)            constant   \n",
      "18             relu      0.0001                        5            constant   \n",
      "19             relu      0.0001                   (5, 5)            constant   \n",
      "20             relu      0.0001                       10            constant   \n",
      "21             relu      0.0001                 (10, 10)            constant   \n",
      "22             relu      0.0001                  (10, 5)            constant   \n",
      "23             relu      0.0001               (5, 10, 5)            constant   \n",
      "24             relu      0.0001             (15, 30, 15)            constant   \n",
      "25             relu      0.0001           (5, 10, 10, 5)            constant   \n",
      "26             relu      0.0001              (15, 30, 5)            constant   \n",
      "27             relu        0.05                        5            constant   \n",
      "28             relu        0.05                   (5, 5)            constant   \n",
      "29             relu        0.05                       10            constant   \n",
      "30             relu        0.05                 (10, 10)            constant   \n",
      "31             relu        0.05                  (10, 5)            constant   \n",
      "32             relu        0.05               (5, 10, 5)            constant   \n",
      "33             relu        0.05             (15, 30, 15)            constant   \n",
      "34             relu        0.05           (5, 10, 10, 5)            constant   \n",
      "35             relu        0.05              (15, 30, 5)            constant   \n",
      "\n",
      "   param_solver                                             params  \\\n",
      "0          adam  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...   \n",
      "1          adam  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...   \n",
      "2          adam  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...   \n",
      "3          adam  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...   \n",
      "4          adam  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...   \n",
      "5          adam  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...   \n",
      "6          adam  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...   \n",
      "7          adam  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...   \n",
      "8          adam  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...   \n",
      "9          adam  {'activation': 'tanh', 'alpha': 0.05, 'hidden_...   \n",
      "10         adam  {'activation': 'tanh', 'alpha': 0.05, 'hidden_...   \n",
      "11         adam  {'activation': 'tanh', 'alpha': 0.05, 'hidden_...   \n",
      "12         adam  {'activation': 'tanh', 'alpha': 0.05, 'hidden_...   \n",
      "13         adam  {'activation': 'tanh', 'alpha': 0.05, 'hidden_...   \n",
      "14         adam  {'activation': 'tanh', 'alpha': 0.05, 'hidden_...   \n",
      "15         adam  {'activation': 'tanh', 'alpha': 0.05, 'hidden_...   \n",
      "16         adam  {'activation': 'tanh', 'alpha': 0.05, 'hidden_...   \n",
      "17         adam  {'activation': 'tanh', 'alpha': 0.05, 'hidden_...   \n",
      "18         adam  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
      "19         adam  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
      "20         adam  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
      "21         adam  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
      "22         adam  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
      "23         adam  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
      "24         adam  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
      "25         adam  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
      "26         adam  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
      "27         adam  {'activation': 'relu', 'alpha': 0.05, 'hidden_...   \n",
      "28         adam  {'activation': 'relu', 'alpha': 0.05, 'hidden_...   \n",
      "29         adam  {'activation': 'relu', 'alpha': 0.05, 'hidden_...   \n",
      "30         adam  {'activation': 'relu', 'alpha': 0.05, 'hidden_...   \n",
      "31         adam  {'activation': 'relu', 'alpha': 0.05, 'hidden_...   \n",
      "32         adam  {'activation': 'relu', 'alpha': 0.05, 'hidden_...   \n",
      "33         adam  {'activation': 'relu', 'alpha': 0.05, 'hidden_...   \n",
      "34         adam  {'activation': 'relu', 'alpha': 0.05, 'hidden_...   \n",
      "35         adam  {'activation': 'relu', 'alpha': 0.05, 'hidden_...   \n",
      "\n",
      "    split0_test_score  split1_test_score  split2_test_score  \\\n",
      "0            0.653614           0.655477           0.649021   \n",
      "1            0.657917           0.675705           0.654401   \n",
      "2            0.658993           0.665591           0.658274   \n",
      "3            0.662435           0.676996           0.665806   \n",
      "4            0.655766           0.669464           0.657413   \n",
      "5            0.659208           0.670755           0.659135   \n",
      "6            0.667814           0.678287           0.652894   \n",
      "7            0.648881           0.664084           0.655692   \n",
      "8            0.662866           0.667527           0.669679   \n",
      "9            0.649096           0.654616           0.636755   \n",
      "10           0.664157           0.674198           0.652894   \n",
      "11           0.650387           0.654185           0.645793   \n",
      "12           0.655981           0.669034           0.662578   \n",
      "13           0.659208           0.667312           0.655907   \n",
      "14           0.656196           0.673983           0.655046   \n",
      "15           0.661575           0.671616           0.660426   \n",
      "16           0.647160           0.637400           0.621691   \n",
      "17           0.653399           0.673122           0.657413   \n",
      "18           0.656627           0.667958           0.639552   \n",
      "19           0.657272           0.662578           0.655046   \n",
      "20           0.655120           0.669464           0.652894   \n",
      "21           0.662866           0.672262           0.654401   \n",
      "22           0.660284           0.670755           0.663008   \n",
      "23           0.649742           0.668603           0.655692   \n",
      "24           0.666093           0.657198           0.661072   \n",
      "25           0.646730           0.671616           0.653755   \n",
      "26           0.662435           0.658489           0.661502   \n",
      "27           0.655981           0.661502           0.645793   \n",
      "28           0.670396           0.663224           0.660211   \n",
      "29           0.650818           0.663654           0.647945   \n",
      "30           0.663081           0.666021           0.661502   \n",
      "31           0.658778           0.680869           0.660641   \n",
      "32           0.649096           0.672046           0.658920   \n",
      "33           0.659639           0.670540           0.658489   \n",
      "34           0.657272           0.669679           0.654831   \n",
      "35           0.658778           0.670971           0.665376   \n",
      "\n",
      "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
      "0            0.656337           0.655261         0.653942        0.002614   \n",
      "1            0.657413           0.671831         0.663454        0.008595   \n",
      "2            0.654401           0.668388         0.661129        0.005110   \n",
      "3            0.662148           0.670755         0.667628        0.005619   \n",
      "4            0.665160           0.666882         0.662937        0.005386   \n",
      "5            0.664515           0.665376         0.663798        0.004341   \n",
      "6            0.664730           0.667312         0.666208        0.008113   \n",
      "7            0.661287           0.666882         0.659365        0.006417   \n",
      "8            0.660426           0.664945         0.665089        0.003278   \n",
      "9            0.644932           0.643856         0.645851        0.005915   \n",
      "10           0.655477           0.663869         0.662119        0.007515   \n",
      "11           0.645147           0.658489         0.650800        0.005055   \n",
      "12           0.661072           0.673553         0.664443        0.006173   \n",
      "13           0.660641           0.672477         0.663109        0.005977   \n",
      "14           0.626210           0.664515         0.655190        0.016006   \n",
      "15           0.662148           0.667527         0.664658        0.004251   \n",
      "16           0.661072           0.639337         0.641332        0.012875   \n",
      "17           0.656553           0.668819         0.661861        0.007678   \n",
      "18           0.650312           0.653970         0.653684        0.009204   \n",
      "19           0.634603           0.664515         0.654803        0.010667   \n",
      "20           0.651388           0.660641         0.657902        0.006579   \n",
      "21           0.657844           0.660641         0.661603        0.006035   \n",
      "22           0.659350           0.667527         0.664185        0.004343   \n",
      "23           0.657629           0.663224         0.658978        0.006459   \n",
      "24           0.659350           0.673122         0.663367        0.005693   \n",
      "25           0.658705           0.666667         0.659494        0.008887   \n",
      "26           0.665806           0.661072         0.661861        0.002367   \n",
      "27           0.644071           0.642780         0.650026        0.007390   \n",
      "28           0.642135           0.643211         0.655835        0.011250   \n",
      "29           0.650097           0.663439         0.655190        0.006888   \n",
      "30           0.662148           0.654185         0.661387        0.003919   \n",
      "31           0.659781           0.667312         0.665476        0.008258   \n",
      "32           0.648590           0.662578         0.658246        0.008793   \n",
      "33           0.662148           0.667097         0.663583        0.004568   \n",
      "34           0.658274           0.649666         0.657945        0.006580   \n",
      "35           0.658489           0.667312         0.664185        0.004877   \n",
      "\n",
      "    rank_test_score  \n",
      "0                31  \n",
      "1                11  \n",
      "2                20  \n",
      "3                 1  \n",
      "4                14  \n",
      "5                 9  \n",
      "6                 2  \n",
      "7                22  \n",
      "8                 4  \n",
      "9                35  \n",
      "10               15  \n",
      "11               33  \n",
      "12                6  \n",
      "13               13  \n",
      "14               29  \n",
      "15                5  \n",
      "16               36  \n",
      "17               16  \n",
      "18               32  \n",
      "19               30  \n",
      "20               26  \n",
      "21               18  \n",
      "22                8  \n",
      "23               23  \n",
      "24               12  \n",
      "25               21  \n",
      "26               17  \n",
      "27               34  \n",
      "28               27  \n",
      "29               28  \n",
      "30               19  \n",
      "31                3  \n",
      "32               24  \n",
      "33               10  \n",
      "34               25  \n",
      "35                7  \n",
      "Best test set score: 0.6676280423733114 with {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10, 10), 'learning_rate': 'constant', 'solver': 'adam'} parameters.\n",
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.49      0.56      1291\n",
      "           1       0.76      0.87      0.81      2434\n",
      "\n",
      "    accuracy                           0.74      3725\n",
      "   macro avg       0.71      0.68      0.69      3725\n",
      "weighted avg       0.73      0.74      0.72      3725\n",
      "\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}