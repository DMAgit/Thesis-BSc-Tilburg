{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Getting elevation from lat/long and making a new csv file which contains elevation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing necessary packages for getting data and making it into the final dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you have the full dataset (CSV file) with the elevation, you won't need to run the next 4 cells."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "Function to get elevation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# script for returning elevation from lat, long, based on open elevation data\n",
    "# which in turn is based on SRTM\n",
    "def get_elevation(lat: float, long: float):\n",
    "    \"\"\"\n",
    "    :param lat: latitude coordinates of the point\n",
    "    :param long: longitude coordinates of the point\n",
    "    :return: elevation in meters as numpy.int64\n",
    "    \"\"\"\n",
    "    query = ('https://api.open-elevation.com/api/v1/lookup'\n",
    "             f'?locations={lat},{long}')\n",
    "    r = requests.get(query).json()  # json object, various ways you can extract value\n",
    "    # one approach is to use pandas json functionality:\n",
    "    elevation = pd.json_normalize(r, 'results')['elevation'].values[0]\n",
    "    return elevation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting the latitude and longitude points from the CSV file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dfFullNoElevation = pd.read_csv(filepath_or_buffer=r\"D:\\Google Drive\\Uni\\Tilburg\\Semester 6\\Thesis\\Data\\FW_Veg_Rem_Combined.csv\")\n",
    "dfLatLong = dfFullNoElevation[[\"latitude\", \"longitude\"]]\n",
    "\n",
    "# dfLatLong"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Script to get the elevation. Takes a while. When I ran it, it took almost 10hrs to complete."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-17-ab9ebacf98dc>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrow\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdfLatLong\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miterrows\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m     \u001B[0melevation\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_elevation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"latitude\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrow\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"longitude\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mindex\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;36m100\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m         \u001B[1;31m# print(f\"{index} done.\")  # useful for dev purposes, allows you to see the progress\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-2-c9f68943e18a>\u001B[0m in \u001B[0;36mget_elevation\u001B[1;34m(lat, long)\u001B[0m\n\u001B[0;32m     11\u001B[0m     query = ('https://api.open-elevation.com/api/v1/lookup'\n\u001B[0;32m     12\u001B[0m              f'?locations={lat},{long}')\n\u001B[1;32m---> 13\u001B[1;33m     \u001B[0mr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrequests\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mquery\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjson\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# json object, various ways you can extract value\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m     \u001B[1;31m# one approach is to use pandas json functionality:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m     \u001B[0melevation\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjson_normalize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'results'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'elevation'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pycharmprojects\\thesis\\lib\\site-packages\\requests\\api.py\u001B[0m in \u001B[0;36mget\u001B[1;34m(url, params, **kwargs)\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m     \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msetdefault\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'allow_redirects'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 76\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mrequest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'get'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     77\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     78\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pycharmprojects\\thesis\\lib\\site-packages\\requests\\api.py\u001B[0m in \u001B[0;36mrequest\u001B[1;34m(method, url, **kwargs)\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[1;31m# cases, and look like a memory leak in others.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     60\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0msessions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSession\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0msession\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 61\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0msession\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0murl\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     62\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pycharmprojects\\thesis\\lib\\site-packages\\requests\\sessions.py\u001B[0m in \u001B[0;36mrequest\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    540\u001B[0m         }\n\u001B[0;32m    541\u001B[0m         \u001B[0msend_kwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msettings\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 542\u001B[1;33m         \u001B[0mresp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprep\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0msend_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    543\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    544\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mresp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pycharmprojects\\thesis\\lib\\site-packages\\requests\\sessions.py\u001B[0m in \u001B[0;36msend\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    653\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    654\u001B[0m         \u001B[1;31m# Send the request\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 655\u001B[1;33m         \u001B[0mr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0madapter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    656\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    657\u001B[0m         \u001B[1;31m# Total elapsed time of the request (approximately)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pycharmprojects\\thesis\\lib\\site-packages\\requests\\adapters.py\u001B[0m in \u001B[0;36msend\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    437\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    438\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mchunked\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 439\u001B[1;33m                 resp = conn.urlopen(\n\u001B[0m\u001B[0;32m    440\u001B[0m                     \u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    441\u001B[0m                     \u001B[0murl\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pycharmprojects\\thesis\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36murlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[0;32m    697\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    698\u001B[0m             \u001B[1;31m# Make the request on the httplib connection object.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 699\u001B[1;33m             httplib_response = self._make_request(\n\u001B[0m\u001B[0;32m    700\u001B[0m                 \u001B[0mconn\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    701\u001B[0m                 \u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pycharmprojects\\thesis\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36m_make_request\u001B[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[0;32m    380\u001B[0m         \u001B[1;31m# Trigger any extra validation we need to do.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    381\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 382\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_validate_conn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    383\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mSocketTimeout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mBaseSSLError\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    384\u001B[0m             \u001B[1;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pycharmprojects\\thesis\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36m_validate_conn\u001B[1;34m(self, conn)\u001B[0m\n\u001B[0;32m   1008\u001B[0m         \u001B[1;31m# Force connect early to allow us to validate the connection.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1009\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"sock\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# AppEngine might not have  `.sock`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1010\u001B[1;33m             \u001B[0mconn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconnect\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1011\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1012\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mconn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_verified\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pycharmprojects\\thesis\\lib\\site-packages\\urllib3\\connection.py\u001B[0m in \u001B[0;36mconnect\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    409\u001B[0m             \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_default_certs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    410\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 411\u001B[1;33m         self.sock = ssl_wrap_socket(\n\u001B[0m\u001B[0;32m    412\u001B[0m             \u001B[0msock\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconn\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    413\u001B[0m             \u001B[0mkeyfile\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkey_file\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pycharmprojects\\thesis\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001B[0m in \u001B[0;36mssl_wrap_socket\u001B[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001B[0m\n\u001B[0;32m    426\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    427\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0msend_sni\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 428\u001B[1;33m         ssl_sock = _ssl_wrap_socket_impl(\n\u001B[0m\u001B[0;32m    429\u001B[0m             \u001B[0msock\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtls_in_tls\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mserver_hostname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mserver_hostname\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    430\u001B[0m         )\n",
      "\u001B[1;32md:\\pycharmprojects\\thesis\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001B[0m in \u001B[0;36m_ssl_wrap_socket_impl\u001B[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001B[0m\n\u001B[0;32m    470\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    471\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mserver_hostname\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 472\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mssl_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrap_socket\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msock\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mserver_hostname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mserver_hostname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    473\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    474\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mssl_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrap_socket\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msock\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\ssl.py\u001B[0m in \u001B[0;36mwrap_socket\u001B[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001B[0m\n\u001B[0;32m    498\u001B[0m         \u001B[1;31m# SSLSocket class handles server_hostname encoding before it calls\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    499\u001B[0m         \u001B[1;31m# ctx._wrap_socket()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 500\u001B[1;33m         return self.sslsocket_class._create(\n\u001B[0m\u001B[0;32m    501\u001B[0m             \u001B[0msock\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msock\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    502\u001B[0m             \u001B[0mserver_side\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mserver_side\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\ssl.py\u001B[0m in \u001B[0;36m_create\u001B[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001B[0m\n\u001B[0;32m   1038\u001B[0m                         \u001B[1;31m# non-blocking\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1039\u001B[0m                         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1040\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdo_handshake\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1041\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mOSError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1042\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\ssl.py\u001B[0m in \u001B[0;36mdo_handshake\u001B[1;34m(self, block)\u001B[0m\n\u001B[0;32m   1307\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0.0\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mblock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1308\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msettimeout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1309\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sslobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdo_handshake\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1310\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1311\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msettimeout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# import time  # optional for timing the code\n",
    "\n",
    "dfElevation = pd.DataFrame()\n",
    "\n",
    "# tic = time.perf_counter()  # timing start\n",
    "\n",
    "for index, row in dfLatLong.iterrows():\n",
    "    elevation = get_elevation(row[\"latitude\"], row[\"longitude\"])\n",
    "    if index % 100 == 0:\n",
    "        # print(f\"{index} done.\")  # useful for dev purposes, allows you to see the progress\n",
    "        pass  # in case the printing is commented out\n",
    "    dfElevation = dfElevation.append([elevation], ignore_index=True)\n",
    "\n",
    "# toc = time.perf_counter()  # timing end\n",
    "dfElevation.columns = [\"elevation\"]\n",
    "dfElevation.head(10)\n",
    "# print(f\"Done in {toc - tic:0.4f} seconds\")  # print the time elapsed\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will want to get the day of the week of the discovery of the fire. First we convert the disc_clean_date to a datetime object, then from it, we get the day of the week.\n",
    "\n",
    "Finally, in order to reduce the complexity of the data, I change it into a boolean column - weekdays are set to True and weekends to False."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "dfFullNoElevation = pd.read_csv(filepath_or_buffer=r\"D:\\Google Drive\\Uni\\Tilburg\\Semester 6\\Thesis\\Data\\FW_Veg_Rem_Combined.csv\")\n",
    "dfFullNoElevation[\"disc_date_datetime\"] = pd.to_datetime(dfFullNoElevation[\"disc_clean_date\"], format=\"%m%d%Y\", infer_datetime_format=True)  # create a new column which contains the datetime objects\n",
    "dfFullNoElevation[\"disc_dow\"] = dfFullNoElevation[\"disc_date_datetime\"].dt.weekday  # create a column which contains the day of week (dow)\n",
    "\n",
    "dfFullNoElevation[\"weekday\"] = dfFullNoElevation[\"disc_dow\"].map({0: True, 1: True, 2: True, 3: True, 4: True, 5:False, 6:False})\n",
    "dfFullNoElevation.drop(labels=\"disc_dow\", axis= 1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting the elevation and date data into the full dataset. Writing it into a CSV file. This is useful so you don't have to run the code above every time you need to generate the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "dfFull = pd.concat([dfFullNoElevation, dfElevation], axis=1)\n",
    "#dfFull.head(10)\n",
    "dfFull.to_csv(path_or_buf=r\"D:\\Google Drive\\Uni\\Tilburg\\Semester 6\\Thesis\\Data\\fullWithElevation.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In case you already have the dataset (CSV file) with the elevation you can just run this part. It will import directly from the CSV into a Pandas DataFrame and run some necessary transformations/selections to produce the final dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "dfFull = pd.read_csv(filepath_or_buffer=r\"D:\\Google Drive\\Uni\\Tilburg\\Semester 6\\Thesis\\Data\\fullWithElevation.csv\")\n",
    "# dfFull.head(10)\n",
    "\n",
    "dfFull = dfFull[[\"fire_size_class\", \"latitude\", \"longitude\", \"discovery_month\", \"weekday\", \"Temp_pre_30\", \"Temp_pre_15\", \"Temp_pre_7\", \"Wind_pre_30\", \"Wind_pre_15\", \"Wind_pre_7\", \"Hum_pre_30\", \"Hum_pre_15\", \"Hum_pre_7\", \"Prec_pre_30\", \"Prec_pre_15\", \"Prec_pre_7\", \"Vegetation\", \"remoteness\", \"elevation\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we can see there's some missing weather data. It's marked with a -1 rather than an NA. Let's fix that and try to drop the NA's."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (55367, 20)\n",
      "after (41118, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"before\", dfFull.shape)\n",
    "\n",
    "dfFull.replace(-1.0, np.NaN, inplace=True)\n",
    "dfFull.dropna(inplace=True)\n",
    "print(\"after\", dfFull.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unfortunately we end up losing about 20% of our data...\n",
    "\n",
    "> Perhaps, since we'll be splitting up the dataset, we can limit ourselves to a using this smaller dataset only when dealing with the weather variables."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next up, we'll want to sort out our weather data.\n",
    "\n",
    "Right now, for each weather variable, we have data from 30 days before, 15 days before, and 7 days before. In order to reduce the number of features, I take the average of the three values, store it in a new column in the DataFrame, and drop the old columns."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41118, 12)\n"
     ]
    }
   ],
   "source": [
    "dfFull[\"Temp\"] = dfFull.loc[:, [\"Temp_pre_30\", \"Temp_pre_15\", \"Temp_pre_7\"]].mean(axis=1)  # get the temperature\n",
    "dfFull.drop(labels=[\"Temp_pre_30\", \"Temp_pre_15\", \"Temp_pre_7\"], axis=1, inplace=True)  # drop the old temps\n",
    "\n",
    "dfFull[\"Wind\"] = dfFull.loc[:, [\"Wind_pre_30\", \"Wind_pre_15\", \"Wind_pre_7\"]].mean(axis=1)  # get the wind\n",
    "dfFull.drop(labels=[\"Wind_pre_30\", \"Wind_pre_15\", \"Wind_pre_7\"], axis=1, inplace=True)  # drop the old winds\n",
    "\n",
    "dfFull[\"Humidity\"] = dfFull.loc[:, [\"Hum_pre_30\", \"Hum_pre_15\", \"Hum_pre_7\"]].mean(axis=1)  # get the humidity\n",
    "dfFull.drop(labels=[\"Hum_pre_30\", \"Hum_pre_15\", \"Hum_pre_7\"], axis=1, inplace=True)  # drop the old humidities\n",
    "\n",
    "dfFull[\"Precipitation\"] = dfFull.loc[:, [\"Prec_pre_30\", \"Prec_pre_15\", \"Prec_pre_7\"]].mean(axis=1)  # get the humidity\n",
    "dfFull.drop(labels=[\"Prec_pre_30\", \"Prec_pre_15\", \"Prec_pre_7\"], axis=1, inplace=True)  # drop the old humidities\n",
    "\n",
    "print(dfFull.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Upon further inspection, it's evident that there's still some missing data. For some fires, all 4 weather variables are 0. It would be normal to see a 0 for one or two of them (for example, if there was no rain at all), but it seems wrong that it could happen for all 4.\n",
    "\n",
    "Let's drop the rows in which all 4 weather columns == 0."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38562, 12)\n"
     ]
    }
   ],
   "source": [
    "dfTemp = dfFull.query(\"Temp == 0 & Wind == 0 & Humidity == 0 & Precipitation == 0\")  # create a new DataFrame that has only the 0 values\n",
    "\n",
    "dfFull = dfFull.loc[dfFull.index.difference(dfTemp.index), ]\n",
    "print(dfFull.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After some research, I have found that having a relative humidity of 0% is pretty much an impossibility ([quick Google source](https://www.chicagotribune.com/news/ct-xpm-2011-12-16-ct-wea-1216-asktom-20111216-story.html)). Even if it's possible for short periods of time, it wouldn't be sustained over 30 days.\n",
    "\n",
    "So, I've decided to consider such rows wrong (measurement error or missing data, take your pick) and thus drop them."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37247, 12)\n"
     ]
    }
   ],
   "source": [
    "dfTemp = dfFull.query(\"Humidity == 0\")\n",
    "\n",
    "dfFull = dfFull.loc[dfFull.index.difference(dfTemp.index), ]\n",
    "print(dfFull.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Change the vegetation column's values from numbers into the actual category it is indicating."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "dfFull.loc[(dfFull.Vegetation == 0), \"Vegetation\"] = np.NaN\n",
    "dfFull.dropna(inplace=True)\n",
    "\n",
    "dfFull.loc[(dfFull.Vegetation == 1), \"Vegetation\"] = \"Tropical Evergreen Broadleaf Forest\"\n",
    "dfFull.loc[(dfFull.Vegetation == 2), \"Vegetation\"] = \"Tropical Deciduous Broadleaf Forest\"\n",
    "dfFull.loc[(dfFull.Vegetation == 3), \"Vegetation\"] = \"Temperate Evergreen Broadleaf Forest\"\n",
    "dfFull.loc[(dfFull.Vegetation == 4), \"Vegetation\"] = \"Temperate Evergreen Needleleaf Forest\"\n",
    "dfFull.loc[(dfFull.Vegetation == 5), \"Vegetation\"] = \"Temperate Deciduous Broadleaf Forest\"\n",
    "dfFull.loc[(dfFull.Vegetation == 6), \"Vegetation\"] = \"Boreal Evergreen Needleleaf Forest\"\n",
    "dfFull.loc[(dfFull.Vegetation == 7), \"Vegetation\"] = \"Boreal Deciduous Needleleaf Forest\"\n",
    "dfFull.loc[(dfFull.Vegetation == 8), \"Vegetation\"] = \"Savanna\"\n",
    "dfFull.loc[(dfFull.Vegetation == 9), \"Vegetation\"] = \"Grassland\"\n",
    "dfFull.loc[(dfFull.Vegetation == 10), \"Vegetation\"] = \"Grassland\"\n",
    "dfFull.loc[(dfFull.Vegetation == 11), \"Vegetation\"] = \"Dense Shrubland\"\n",
    "dfFull.loc[(dfFull.Vegetation == 12), \"Vegetation\"] = \"Open Shrubland\"\n",
    "dfFull.loc[(dfFull.Vegetation == 13), \"Vegetation\"] = \"Tundra\"\n",
    "dfFull.loc[(dfFull.Vegetation == 14), \"Vegetation\"] = \"Desert\"\n",
    "dfFull.loc[(dfFull.Vegetation == 15), \"Vegetation\"] = \"Rock/Ice\"\n",
    "dfFull.loc[(dfFull.Vegetation == 16), \"Vegetation\"] = \"Tropical Evergreen Broadleaf Forest\"\n",
    "dfFull.loc[(dfFull.Vegetation == 17), \"Vegetation\"] = \"Tropical Deciduous Broadleaf Forest\"\n",
    "dfFull.loc[(dfFull.Vegetation == 18), \"Vegetation\"] = \"Temperate Evergreen Broadleaf Forest\"\n",
    "dfFull.loc[(dfFull.Vegetation == 19), \"Vegetation\"] = \"Temperate Evergreen Needleleaf Forest\"\n",
    "dfFull.loc[(dfFull.Vegetation == 20), \"Vegetation\"] = \"Temperate Deciduous Broadleaf Forest\"\n",
    "dfFull.loc[(dfFull.Vegetation == 21), \"Vegetation\"] = \"Boreal Evergreen Needleleaf Forest\"\n",
    "dfFull.loc[(dfFull.Vegetation == 22), \"Vegetation\"] = \"Boreal Deciduous Needleleaf Forest\"\n",
    "dfFull.loc[(dfFull.Vegetation == 23), \"Vegetation\"] = \"Water\"\n",
    "dfFull.loc[(dfFull.Vegetation == 24), \"Vegetation\"] = \"Cropland\"\n",
    "dfFull.loc[(dfFull.Vegetation == 25), \"Vegetation\"] = \"Cropland\"\n",
    "dfFull.loc[(dfFull.Vegetation == 26), \"Vegetation\"] = \"Pastureland\"\n",
    "dfFull.loc[(dfFull.Vegetation == 27), \"Vegetation\"] = \"Pastureland\"\n",
    "dfFull.loc[(dfFull.Vegetation == 28), \"Vegetation\"] = \"Urban\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Overall, the dataset's size has been reduced quite a lot. This is not ideal, but in starting out with over 50k samples, the dataset should still be large enough (30k samples) to perform our training and testing procedures.\n",
    "\n",
    "> Hopefully, when not using the weather features, I will be able to use the full dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the final dataset into a CSV."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "dfFull.reset_index(drop=True, inplace=True)  # reset the index into a nice and clean one, discarding the old one\n",
    "dfFull.to_csv(path_or_buf=r\"fullDataFinal.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We're done!\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}