{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Getting elevation from lat/long and making a new csv file which contains elevation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing necessary packages for getting data and making it into the final dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you have the full dataset (CSV file) with the elevation, you won't need to run the next 4 cells."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "Function to get elevation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# script for returning elevation from lat, long, based on open elevation data\n",
    "# which in turn is based on SRTM\n",
    "def get_elevation(lat: float, long: float):\n",
    "    \"\"\"\n",
    "    :param lat: latitude coordinates of the point\n",
    "    :param long: longitude coordinates of the point\n",
    "    :return: elevation in meters as numpy.int64\n",
    "    \"\"\"\n",
    "    query = ('https://api.open-elevation.com/api/v1/lookup'\n",
    "             f'?locations={lat},{long}')\n",
    "    r = requests.get(query).json()  # json object, various ways you can extract value\n",
    "    # one approach is to use pandas json functionality:\n",
    "    elevation = pd.json_normalize(r, 'results')['elevation'].values[0]\n",
    "    return elevation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting the latitude and longitude points from the CSV file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "dfFullNoElevation = pd.read_csv(filepath_or_buffer=r\"D:\\Google Drive\\Uni\\Tilburg\\Semester 6\\Thesis\\Data\\FW_Veg_Rem_Combined.csv\")\n",
    "dfLatLong = dfFullNoElevation[[\"latitude\", \"longitude\"]]\n",
    "\n",
    "# dfLatLong"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Script to get the elevation. Takes a while. When I ran it, it took almost 10hrs to complete."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfLatLong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-7a0e80f0ae83>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;31m# tic = time.perf_counter()  # timing start\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrow\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdfLatLong\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miterrows\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m     \u001B[0melevation\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_elevation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"latitude\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrow\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"longitude\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mindex\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;36m100\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dfLatLong' is not defined"
     ]
    }
   ],
   "source": [
    "# import time  # optional for timing the code\n",
    "\n",
    "dfElevation = pd.DataFrame(columns=[\"elevation\"])\n",
    "\n",
    "# tic = time.perf_counter()  # timing start\n",
    "\n",
    "for index, row in dfLatLong.iterrows():\n",
    "    elevation = get_elevation(row[\"latitude\"], row[\"longitude\"])\n",
    "    if index % 100 == 0:\n",
    "        # print(f\"{index} done.\")  # useful for dev purposes, allows you to see the progress\n",
    "        pass  # in case the printing is commented out\n",
    "    dfElevation = dfElevation.append([elevation], ignore_index=True)\n",
    "\n",
    "# toc = time.perf_counter()  # timing end\n",
    "\n",
    "dfElevation.columns = [\"elevation\"]  # change the column label\n",
    "dfElevation.head(10)\n",
    "# print(f\"Done in {toc - tic:0.4f} seconds\")  # print the time elapsed\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will want to get the day of the week of the discovery of the fire. First we convert the disc_clean_date to a datetime object."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "dfFullNoElevation = pd.read_csv(filepath_or_buffer=r\"D:\\Google Drive\\Uni\\Tilburg\\Semester 6\\Thesis\\Data\\FW_Veg_Rem_Combined.csv\")\n",
    "dfFullNoElevation[\"disc_date_datetime\"] = pd.to_datetime(dfFullNoElevation[\"disc_clean_date\"], format=\"%m%d%Y\", infer_datetime_format=True)  # create a new column which contains the datetime objects\n",
    "dfFullNoElevation[\"disc_dow\"] = dfFullNoElevation[\"disc_date_datetime\"].dt.dayofweek  # create a column which contains the day of week (dow)\n",
    "# 0 - Monday; 1 - Tuesday; ...; 6 - Sunday;"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting the elevation and date data into the full dataset. Writing it into a CSV file. This is useful so you don't have to run the code above every time you need to generate the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfFullNoElevation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-6e0a717734b3>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdfFull\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mdfFullNoElevation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdfElevation\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;31m#dfFull.head(10)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mdfFull\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath_or_buf\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34mr\"D:\\Google Drive\\Uni\\Tilburg\\Semester 6\\Thesis\\Data\\fullWithElevation.csv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dfFullNoElevation' is not defined"
     ]
    }
   ],
   "source": [
    "dfFull = pd.concat([dfFullNoElevation, dfElevation], axis=1)\n",
    "#dfFull.head(10)\n",
    "dfFull.to_csv(path_or_buf=r\"D:\\Google Drive\\Uni\\Tilburg\\Semester 6\\Thesis\\Data\\fullWithElevation.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In case you already have the dataset (CSV file) with the elevation you can just run this part. It will import directly from the CSV into a Pandas DataFrame and run some necessary transformations/selections to produce the final dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "dfFull = pd.read_csv(filepath_or_buffer=r\"D:\\Google Drive\\Uni\\Tilburg\\Semester 6\\Thesis\\Data\\fullWithElevation.csv\")\n",
    "# dfFull.head(10)\n",
    "\n",
    "dfFull = dfFull[[\"fire_size_class\", \"latitude\", \"longitude\", \"discovery_month\", \"disc_dow\", \"Temp_pre_30\", \"Temp_pre_15\", \"Temp_pre_7\", \"Wind_pre_30\", \"Wind_pre_15\", \"Wind_pre_7\", \"Hum_pre_30\", \"Hum_pre_15\", \"Hum_pre_7\", \"Prec_pre_30\", \"Prec_pre_15\", \"Prec_pre_7\", \"Vegetation\", \"remoteness\", \"elevation\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we can see there's some missing weather data. It's marked with a -1 rather than an NA. Let's fix that and try to drop the NA's."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (55367, 20)\n",
      "after (41118, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"before\", dfFull.shape)\n",
    "\n",
    "dfFull.replace(-1.0, np.NaN, inplace=True)\n",
    "dfFull.dropna(inplace=True)\n",
    "print(\"after\", dfFull.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unfortunately we end up losing about 20% of our data...\n",
    "\n",
    "> Perhaps, since we'll be splitting up the dataset, we can limit ourselves to a using this smaller dataset only when dealing with the weather variables."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next up, we'll want to sort out our weather data.\n",
    "\n",
    "Right now, for each weather variable, we have data from 30 days before, 15 days before, and 7 days before. In order to reduce the number of features, I take the average of the three values, store it in a new column in the DataFrame, and drop the old columns."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41118, 12)\n"
     ]
    }
   ],
   "source": [
    "dfFull[\"Temp\"] = dfFull.loc[:, [\"Temp_pre_30\", \"Temp_pre_15\", \"Temp_pre_7\"]].mean(axis=1)  # get the temperature\n",
    "dfFull.drop(labels=[\"Temp_pre_30\", \"Temp_pre_15\", \"Temp_pre_7\"], axis=1, inplace=True)  # drop the old temps\n",
    "\n",
    "dfFull[\"Wind\"] = dfFull.loc[:, [\"Wind_pre_30\", \"Wind_pre_15\", \"Wind_pre_7\"]].mean(axis=1)  # get the wind\n",
    "dfFull.drop(labels=[\"Wind_pre_30\", \"Wind_pre_15\", \"Wind_pre_7\"], axis=1, inplace=True)  # drop the old winds\n",
    "\n",
    "dfFull[\"Humidity\"] = dfFull.loc[:, [\"Hum_pre_30\", \"Hum_pre_15\", \"Hum_pre_7\"]].mean(axis=1)  # get the humidity\n",
    "dfFull.drop(labels=[\"Hum_pre_30\", \"Hum_pre_15\", \"Hum_pre_7\"], axis=1, inplace=True)  # drop the old humidities\n",
    "\n",
    "dfFull[\"Precipitation\"] = dfFull.loc[:, [\"Prec_pre_30\", \"Prec_pre_15\", \"Prec_pre_7\"]].mean(axis=1)  # get the humidity\n",
    "dfFull.drop(labels=[\"Prec_pre_30\", \"Prec_pre_15\", \"Prec_pre_7\"], axis=1, inplace=True)  # drop the old humidities\n",
    "\n",
    "print(dfFull.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Upon further inspection, it's evident that there's still some missing data. For some fires, all 4 weather variables are 0. It would be normal to see a 0 for one or two of them (for example, if there was no rain at all), but it seems wrong that it could happen for all 4.\n",
    "\n",
    "Let's drop the rows in which all 4 weather columns == 0."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38562, 12)\n"
     ]
    }
   ],
   "source": [
    "dfTemp = dfFull.query(\"Temp == 0 & Wind == 0 & Humidity == 0 & Precipitation == 0\")  # create a new DataFrame that has only the 0 values\n",
    "\n",
    "dfFull = dfFull.loc[dfFull.index.difference(dfTemp.index), ]\n",
    "print(dfFull.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After some research, I have found that having a relative humidity of 0% is pretty much an impossibility ([quick Google source](https://www.chicagotribune.com/news/ct-xpm-2011-12-16-ct-wea-1216-asktom-20111216-story.html)). Even if it's possible for short periods of time, it wouldn't be sustained over 30 days.\n",
    "\n",
    "So, I've decided to consider such rows wrong (measurement error or missing data, take your pick) and thus drop them."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37247, 12)\n"
     ]
    }
   ],
   "source": [
    "dfTemp = dfFull.query(\"Humidity == 0\")\n",
    "\n",
    "dfFull = dfFull.loc[dfFull.index.difference(dfTemp.index), ]\n",
    "print(dfFull.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Overall, the dataset's size has been reduced quite a lot. This is not ideal, but in starting out with over 50k samples, the dataset should still be large enough (37k+ samples) to perform our training and testing procedures.\n",
    "\n",
    "> Hopefully, when not using the weather features, I will be able to use the full dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the final dataset into a CSV."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "dfFull.to_csv(path_or_buf=r\"D:\\Google Drive\\Uni\\Tilburg\\Semester 6\\Thesis\\Data\\fullDataFinal.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We're done!\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}